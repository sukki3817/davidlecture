#getting to the working dir
cd class/session_2/
## i can also login to the account 
###sulky231@nesh-fe.rz.uni-kiel.de , password: ooGh4huli

#checking where is the data
ls -thrl /gxfs_work1/cau/sulky231/data
ls -thrl /gxfs_work1/cau/sulky231/data_analysis/

#we can also count the number of reads in each sample, let's do it for just the forward reads (R1) because the reverse will match.
###check the header
zcat /gxfs_work1/cau/sulky231/data/BB04* | head -n 4
###use the header, count the number of reads in each sample 
zgrep -c "@A00556:330:HMCLCDRX2" /gxfs_work1/cau/sulky231/data/*R1*gz
##/gxfs_work1/cau/sulky231/data/BB04_1m_spike.R1.fastq.gz:21359413
##/gxfs_work1/cau/sulky231/data/BB04_25m_spike.R1.fastq.gz:18973661
##/gxfs_work1/cau/sulky231/data/BB04_55m_spike.R1.fastq.gz:39062029
##/gxfs_work1/cau/sulky231/data/BB04_70m_spike.R1.fastq.gz:43310188
##/gxfs_work1/cau/sulky231/data/BB23_60m_spike.R1.fastq.gz:42258580
##/gxfs_work1/cau/sulky231/data/GB96_150m_spike.R1.fastq.gz:26468603
##/gxfs_work1/cau/sulky231/data/GB96_1m_spike.R1.fastq.gz:22349374
##/gxfs_work1/cau/sulky231/data/GB96_25m_spike.R1.fastq.gz:22675362
##/gxfs_work1/cau/sulky231/data/GB96_50m_spike.R1.fastq.gz:27198472
##/gxfs_work1/cau/sulky231/data/Hackflex_Blank.R1.fastq.gz:735
##/gxfs_work1/cau/sulky231/data/KBP568_Jan_25m_nospike.R1.fastq.gz:45560313
##/gxfs_work1/cau/sulky231/data/KBP569_Feb_25m_nospike.R1.fastq.gz:36224875
##/gxfs_work1/cau/sulky231/data/KBP_Aug_25m_nospike.R1.fastq.gz:41951464
##/gxfs_work1/cau/sulky231/data/KBP_July_25m_nospike.R1.fastq.gz:26739455
##/gxfs_work1/cau/sulky231/data/KBP_Mar_25m_nospike.R1.fastq.gz:34277232
##/gxfs_work1/cau/sulky231/data/KBP_May_25m_nospike.R1.fastq.gz:32360542

mkdir data_analysis
cd data_analysis
cp /gxfs_work1/cau/sulky231/data_analysis/sample.names .

#trimming, cutting adapters , takes 30min per sample
conda activate trimmomatic
for i in `cat sample.names`
do
sbatch -p cluster -t 1:00:00 --mem=100000 -J cat -o trim.out -e trim.err -n 30 --wrap="trimmomatic PE -threads 30 /gxfs_work1/cau/sulky231/data/$i.R1.fastq.gz /gxfs_work1/cau/sulky231/data/$i.R2.fastq.gz paired-$i.R1.fastq.gz unpaired-$i.R1.fastq.gz paired-$i.R2.fastq.gz unpaired-$i.R2.fastq.gz ILLUMINACLIP:$HOME/miniconda3/envs/trimmomatic/share/trimmomatic-0.39-2/adapters/NexteraPE-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:50:30 MINLEN:50"
done

cat /gxfs_work1/cau/sulky231/data_analysis/spades.500.20.*/contigs.fasta > all.spades.contigs.fasta

conda activate seqtk
seqtk seq -L 5000 all.spades.contigs.fasta > 5k.all.spades.contigs.fasta
conda deactivate

#Clustering with cd-hit-est
conda activate cdhit
sbatch -p cluster -t 12:00:00 --mem=100000 -J cd -o cd.out -e cd.err -n 30 --wrap="cd-hit-est -M 100000 -T 30 -c 0.99 -i 5k.all.spades.contigs.fasta -o cdhit.5k.all.spades.contigs.fasta"


conda activate anvio-7.1
anvi-script-reformat-fasta --simplify-names --prefix c -o rename.cdhit.5k.all.spades.contigs.fasta cdhit.5k.all.spades.contigs.fasta

sbatch -p cluster -t 1:00:00 --mem=100000 -J build -o build.out -e build.err -n 1 --wrap="bowtie2-build rename.cdhit.5k.all.spades.contigs.fasta rename.cdhit.5k.all.spades.contigs.fasta.bt"

for i in `cat sample.names`
do
sbatch -p cluster -t 2:00:00 --mem=100000 -J bow -o bow.out -e bow.err -n 24 --wrap="bowtie2 --threads 24 -x rename.cdhit.5k.all.spades.contigs.fasta.bt -1 paired-$i.R1.fastq.gz -2 paired-$i.R1.fastq.gz --no-unal -S $i.rename.cdhit.5k.all.spades.contigs.fasta.bt.sam"
done


conda activate anvio-7.1
for i in `cat sample.names`
do
sbatch -p cluster -t 12:00:00 --mem=100000 -J cat -o sp.out -e sp.err -n 1 --wrap="anvi-init-bam -o $i.rename.cdhit.5k.all.spades.contigs.fasta.bt.sam.bam $i.rename.cdhit.5k.all.spades.contigs.fasta.bt.sam"
done

#Binning with metabat
##metabat requires a gzipped contigs file
sbatch -n 20 -J gzip -o gzip.out -e gzip.err --wrap="gzip rename.cdhit.5k.all.spades.contigs.fasta"
##prep for binning by metabat, 3 minutes 
sbatch -n 20 -J jgisum -o jgi.out -e jgi.err --wrap="jgi_summarize_bam_contig_depths --outputDepth depth_file_for_metabat.spades.txt *bam"

 
cp /gxfs_work1/cau/sulky231/data_analysis/rename.cdhit.5k.all.spades.contigs.fasta.db .
cp /gxfs_work1/cau/sulky231/data_analysis/merged_samples/PROFILE.db .

ssh -L 8080:localhost:8080 smomw536@nesh-fe.rz.uni-kiel.de
anvi-interactive -c rename.cdhit.5k.all.spades.contigs.fasta.db -p merged_samples/PROFILE.db --server-only -P 8080




